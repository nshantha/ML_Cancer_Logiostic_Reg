{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read Datafile\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv('wdbc.dataset',header = None)\n",
    "data = np.array(dataset)\n",
    "# pd.map({'cat': 'kitten', 'dog': 'puppy'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(X):\n",
    "    \n",
    "    #computing normalization\n",
    "    X_norm = np.linalg.norm(X, axis=1, keepdims = True);\n",
    "    \n",
    "    #dividing main matrix by the normalized value\n",
    "    X = X / X_norm;\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(data)\n",
    "#Splitting input matrix into train,validation and test set\n",
    "X_train, X_valid, X_test = data[:456,2:], data[456:513,2:], data[513:,2:]\n",
    "\n",
    "#Splitting labelled vector into train,validation and test set\n",
    "Y_train, Y_valid, Y_test = data[:456,1:2], data[456:513,1:2], data[513:,1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing input data\n",
    "X_train = normalization(X_train)\n",
    "X_valid = normalization(X_valid)\n",
    "X_test = normalization(X_test)\n",
    "\n",
    "#reshaping the input matrix\n",
    "X_train = X_train.reshape(30,X_train.shape[0])\n",
    "X_valid = X_valid.reshape(30,X_valid.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialization of weights and bias\n",
    "def initialization(dimension):\n",
    "    w = np.zeros((dimension,1))\n",
    "    b = 0.0\n",
    "\n",
    "    return w,b   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    sig = 1/(1+np.exp(-x))\n",
    "    return sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propogation(w,b,X,Y):\n",
    "    \n",
    "    #number of training examples\n",
    "    m = X.shape[1]\n",
    "\n",
    "    #calculating forward propogation\n",
    "    a = sigmoid(np.dot(w.T,X) + b);\n",
    "    \n",
    "    cost = (-1/m) * np.sum(Y * np.log(a) + (1-Y) * np.log(1-a)) \n",
    "    \n",
    "    #calculating back_prop\n",
    "    dw = (1/m)* np.dot(X,(a-Y).T)\n",
    "    db = (1/m)* np.sum(a-Y)\n",
    "\n",
    "    grad_values = {\"dw\": dw,\n",
    "                   \"db\": db}\n",
    "\n",
    "    return cost,grad_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(w, b, X, Y, num_iterations, learning_rate):\n",
    "    \n",
    "    #creating a empty list for cost values\n",
    "    cost_values = []\n",
    "    \n",
    "    #iterating for given number of iterations\n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        #gradient descent calculation\n",
    "        cost,grad_values = propogation(w, b, X, Y)\n",
    "        \n",
    "        dw = grad_values[\"dw\"]\n",
    "        db = grad_values[\"db\"]\n",
    "        \n",
    "        #update w and b\n",
    "        w = w - (learning_rate*dw)\n",
    "        b = b - (learning_rate*db)\n",
    "\n",
    "        # append cost to cost list and print after every 100 iterations\n",
    "        if i % 100 == 0:\n",
    "            cost_values.append(cost)\n",
    "            print (\"Cost after %i iteration : %f\" %(i, cost))\n",
    "            \n",
    "        parameters = {\"w\": w,\n",
    "                      \"b\": b}\n",
    "    \n",
    "        grad_values = {\"dw\": dw,\n",
    "                       \"db\": db}\n",
    "            \n",
    "    return parameters, grad_values, cost_values  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(w,b,X):\n",
    "    \n",
    "    m = X.shape[1]\n",
    "\n",
    "    Y_prediction = np.zeros((1,m))\n",
    "\n",
    "    a =  sigmoid(np.dot(w.T,X)+ b)\n",
    "\n",
    "    for i in range(a.shape[1]):\n",
    "        Y_prediction[0, i] = 1 if a[0, i] > 0.5 else 0\n",
    "    \n",
    "    assert(Y_prediction.shape == (1, m))\n",
    "    return Y_prediction  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, X_valid, Y_train, Y_valid, num_iterations, learning_rate):\n",
    "    \n",
    "    # initialize parameters with 0\n",
    "    w, b = initialization(X_train.shape[0])\n",
    "    \n",
    "    #Gradient_descent\n",
    "    parameters, grad_values, cost_values = gradient_descent(w, b, X_train, Y_train, num_iterations, learning_rate)\n",
    "    \n",
    "    w = parameters[\"w\"]\n",
    "    b = parameters[\"b\"]\n",
    "    \n",
    "    Y_pred_train = logistic_regression(w,b,X_train)\n",
    "    print(\"Y_pred_train shape\",Y_pred_train.shape)\n",
    "    Y_pred_valid = logistic_regression(w,b,X_valid)\n",
    "    print(\"Y_pred_valid shape\",Y_pred_valid.shape)\n",
    "    \n",
    "    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_pred_train - Y_train)) * 100))\n",
    "    print(\"Validation accuracy: {} %\".format(100 - np.mean(np.abs(Y_pred_valid - Y_valid)) * 100))\n",
    "    \n",
    "    model_data = {\"costs\": cost_values,\n",
    "     \"Y_prediction_train\" : Y_pred_train, \n",
    "     \"w\" : w, \n",
    "     \"b\" : b,\n",
    "     \"learning_rate\" : learning_rate,\n",
    "     \"num_iterations\": num_iterations}\n",
    "    \n",
    "    return model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after 0 iteration : 316.075114\n",
      "Cost after 100 iteration : 286.385265\n",
      "Cost after 200 iteration : 275.273911\n",
      "Cost after 300 iteration : 265.490446\n",
      "Cost after 400 iteration : 256.865855\n",
      "Cost after 500 iteration : 249.244852\n",
      "Cost after 600 iteration : 242.488821\n",
      "Cost after 700 iteration : 236.476536\n",
      "Cost after 800 iteration : 231.103470\n",
      "Cost after 900 iteration : 226.280335\n",
      "Cost after 1000 iteration : 221.931297\n",
      "Cost after 1100 iteration : 217.992147\n",
      "Cost after 1200 iteration : 214.408566\n",
      "Cost after 1300 iteration : 211.134586\n",
      "Cost after 1400 iteration : 208.131242\n",
      "Cost after 1500 iteration : 205.365426\n",
      "Cost after 1600 iteration : 202.808924\n",
      "Cost after 1700 iteration : 200.437614\n",
      "Cost after 1800 iteration : 198.230799\n",
      "Cost after 1900 iteration : 196.170656\n",
      "Cost after 2000 iteration : 194.241776\n",
      "Cost after 2100 iteration : 192.430791\n",
      "Cost after 2200 iteration : 190.726058\n",
      "Cost after 2300 iteration : 189.117397\n",
      "Cost after 2400 iteration : 187.595879\n",
      "Cost after 2500 iteration : 186.153642\n",
      "Cost after 2600 iteration : 184.783741\n",
      "Cost after 2700 iteration : 183.480020\n",
      "Cost after 2800 iteration : 182.237005\n",
      "Cost after 2900 iteration : 181.049814\n",
      "Cost after 3000 iteration : 179.914082\n",
      "Cost after 3100 iteration : 178.825889\n",
      "Cost after 3200 iteration : 177.781713\n",
      "Cost after 3300 iteration : 176.778374\n",
      "Cost after 3400 iteration : 175.813000\n",
      "Cost after 3500 iteration : 174.882985\n",
      "Cost after 3600 iteration : 173.985962\n",
      "Cost after 3700 iteration : 173.119777\n",
      "Cost after 3800 iteration : 172.282463\n",
      "Cost after 3900 iteration : 171.472223\n",
      "Cost after 4000 iteration : 170.687409\n",
      "Cost after 4100 iteration : 169.926508\n",
      "Cost after 4200 iteration : 169.188131\n",
      "Cost after 4300 iteration : 168.470995\n",
      "Cost after 4400 iteration : 167.773918\n",
      "Cost after 4500 iteration : 167.095807\n",
      "Cost after 4600 iteration : 166.435650\n",
      "Cost after 4700 iteration : 165.792509\n",
      "Cost after 4800 iteration : 165.165511\n",
      "Cost after 4900 iteration : 164.553847\n",
      "Cost after 5000 iteration : 163.956762\n",
      "Cost after 5100 iteration : 163.373552\n",
      "Cost after 5200 iteration : 162.803561\n",
      "Cost after 5300 iteration : 162.246173\n",
      "Cost after 5400 iteration : 161.700815\n",
      "Cost after 5500 iteration : 161.166947\n",
      "Cost after 5600 iteration : 160.644065\n",
      "Cost after 5700 iteration : 160.131693\n",
      "Cost after 5800 iteration : 159.629387\n",
      "Cost after 5900 iteration : 159.136726\n",
      "Cost after 6000 iteration : 158.653315\n",
      "Cost after 6100 iteration : 158.178782\n",
      "Cost after 6200 iteration : 157.712774\n",
      "Cost after 6300 iteration : 157.254960\n",
      "Cost after 6400 iteration : 156.805025\n",
      "Cost after 6500 iteration : 156.362673\n",
      "Cost after 6600 iteration : 155.927623\n",
      "Cost after 6700 iteration : 155.499606\n",
      "Cost after 6800 iteration : 155.078372\n",
      "Cost after 6900 iteration : 154.663679\n",
      "Cost after 7000 iteration : 154.255300\n",
      "Cost after 7100 iteration : 153.853019\n",
      "Cost after 7200 iteration : 153.456628\n",
      "Cost after 7300 iteration : 153.065933\n",
      "Cost after 7400 iteration : 152.680745\n",
      "Cost after 7500 iteration : 152.300888\n",
      "Cost after 7600 iteration : 151.926192\n",
      "Cost after 7700 iteration : 151.556493\n",
      "Cost after 7800 iteration : 151.191639\n",
      "Cost after 7900 iteration : 150.831480\n",
      "Cost after 8000 iteration : 150.475876\n",
      "Cost after 8100 iteration : 150.124692\n",
      "Cost after 8200 iteration : 149.777798\n",
      "Cost after 8300 iteration : 149.435071\n",
      "Cost after 8400 iteration : 149.096392\n",
      "Cost after 8500 iteration : 148.761648\n",
      "Cost after 8600 iteration : 148.430729\n",
      "Cost after 8700 iteration : 148.103531\n",
      "Cost after 8800 iteration : 147.779954\n",
      "Cost after 8900 iteration : 147.459902\n",
      "Cost after 9000 iteration : 147.143281\n",
      "Cost after 9100 iteration : 146.830003\n",
      "Cost after 9200 iteration : 146.519983\n",
      "Cost after 9300 iteration : 146.213138\n",
      "Cost after 9400 iteration : 145.909389\n",
      "Cost after 9500 iteration : 145.608660\n",
      "Cost after 9600 iteration : 145.310878\n",
      "Cost after 9700 iteration : 145.015972\n",
      "Cost after 9800 iteration : 144.723873\n",
      "Cost after 9900 iteration : 144.434516\n",
      "Cost after 10000 iteration : 144.147838\n",
      "Cost after 10100 iteration : 143.863778\n",
      "Cost after 10200 iteration : 143.582276\n",
      "Cost after 10300 iteration : 143.303275\n",
      "Cost after 10400 iteration : 143.026722\n",
      "Cost after 10500 iteration : 142.752561\n",
      "Cost after 10600 iteration : 142.480742\n",
      "Cost after 10700 iteration : 142.211216\n",
      "Cost after 10800 iteration : 141.943934\n",
      "Cost after 10900 iteration : 141.678849\n",
      "Cost after 11000 iteration : 141.415918\n",
      "Cost after 11100 iteration : 141.155095\n",
      "Cost after 11200 iteration : 140.896339\n",
      "Cost after 11300 iteration : 140.639610\n",
      "Cost after 11400 iteration : 140.384867\n",
      "Cost after 11500 iteration : 140.132072\n",
      "Cost after 11600 iteration : 139.881187\n",
      "Cost after 11700 iteration : 139.632178\n",
      "Cost after 11800 iteration : 139.385009\n",
      "Cost after 11900 iteration : 139.139645\n",
      "Cost after 12000 iteration : 138.896055\n",
      "Cost after 12100 iteration : 138.654205\n",
      "Cost after 12200 iteration : 138.414066\n",
      "Cost after 12300 iteration : 138.175606\n",
      "Cost after 12400 iteration : 137.938797\n",
      "Cost after 12500 iteration : 137.703609\n",
      "Cost after 12600 iteration : 137.470016\n",
      "Cost after 12700 iteration : 137.237991\n",
      "Cost after 12800 iteration : 137.007506\n",
      "Cost after 12900 iteration : 136.778538\n",
      "Cost after 13000 iteration : 136.551060\n",
      "Cost after 13100 iteration : 136.325049\n",
      "Cost after 13200 iteration : 136.100482\n",
      "Cost after 13300 iteration : 135.877335\n",
      "Cost after 13400 iteration : 135.655587\n",
      "Cost after 13500 iteration : 135.435216\n",
      "Cost after 13600 iteration : 135.216200\n",
      "Cost after 13700 iteration : 134.998519\n",
      "Cost after 13800 iteration : 134.782154\n",
      "Cost after 13900 iteration : 134.567084\n",
      "Cost after 14000 iteration : 134.353290\n",
      "Cost after 14100 iteration : 134.140754\n",
      "Cost after 14200 iteration : 133.929459\n",
      "Cost after 14300 iteration : 133.719385\n",
      "Cost after 14400 iteration : 133.510516\n",
      "Cost after 14500 iteration : 133.302836\n",
      "Cost after 14600 iteration : 133.096327\n",
      "Cost after 14700 iteration : 132.890973\n",
      "Cost after 14800 iteration : 132.686760\n",
      "Cost after 14900 iteration : 132.483671\n",
      "Cost after 15000 iteration : 132.281693\n",
      "Cost after 15100 iteration : 132.080809\n",
      "Cost after 15200 iteration : 131.881006\n",
      "Cost after 15300 iteration : 131.682270\n",
      "Cost after 15400 iteration : 131.484588\n",
      "Cost after 15500 iteration : 131.287946\n",
      "Cost after 15600 iteration : 131.092330\n",
      "Cost after 15700 iteration : 130.897729\n",
      "Cost after 15800 iteration : 130.704130\n",
      "Cost after 15900 iteration : 130.511520\n",
      "Cost after 16000 iteration : 130.319888\n",
      "Cost after 16100 iteration : 130.129222\n",
      "Cost after 16200 iteration : 129.939510\n",
      "Cost after 16300 iteration : 129.750742\n",
      "Cost after 16400 iteration : 129.562906\n",
      "Cost after 16500 iteration : 129.375992\n",
      "Cost after 16600 iteration : 129.189989\n",
      "Cost after 16700 iteration : 129.004887\n",
      "Cost after 16800 iteration : 128.820676\n",
      "Cost after 16900 iteration : 128.637345\n",
      "Cost after 17000 iteration : 128.454886\n",
      "Cost after 17100 iteration : 128.273288\n",
      "Cost after 17200 iteration : 128.092543\n",
      "Cost after 17300 iteration : 127.912641\n",
      "Cost after 17400 iteration : 127.733574\n",
      "Cost after 17500 iteration : 127.555332\n",
      "Cost after 17600 iteration : 127.377907\n",
      "Cost after 17700 iteration : 127.201290\n",
      "Cost after 17800 iteration : 127.025474\n",
      "Cost after 17900 iteration : 126.850449\n",
      "Cost after 18000 iteration : 126.676209\n",
      "Cost after 18100 iteration : 126.502744\n",
      "Cost after 18200 iteration : 126.330049\n",
      "Cost after 18300 iteration : 126.158114\n",
      "Cost after 18400 iteration : 125.986933\n",
      "Cost after 18500 iteration : 125.816498\n",
      "Cost after 18600 iteration : 125.646802\n",
      "Cost after 18700 iteration : 125.477838\n",
      "Cost after 18800 iteration : 125.309599\n",
      "Cost after 18900 iteration : 125.142079\n",
      "Cost after 19000 iteration : 124.975270\n",
      "Cost after 19100 iteration : 124.809167\n",
      "Cost after 19200 iteration : 124.643762\n",
      "Cost after 19300 iteration : 124.479049\n",
      "Cost after 19400 iteration : 124.315022\n",
      "Cost after 19500 iteration : 124.151676\n",
      "Cost after 19600 iteration : 123.989003\n",
      "Cost after 19700 iteration : 123.826999\n",
      "Cost after 19800 iteration : 123.665656\n",
      "Cost after 19900 iteration : 123.504970\n",
      "Cost after 20000 iteration : 123.344935\n",
      "Cost after 20100 iteration : 123.185545\n",
      "Cost after 20200 iteration : 123.026794\n",
      "Cost after 20300 iteration : 122.868678\n",
      "Cost after 20400 iteration : 122.711192\n",
      "Cost after 20500 iteration : 122.554329\n",
      "Cost after 20600 iteration : 122.398084\n",
      "Cost after 20700 iteration : 122.242454\n",
      "Cost after 20800 iteration : 122.087432\n",
      "Cost after 20900 iteration : 121.933014\n",
      "Cost after 21000 iteration : 121.779194\n",
      "Cost after 21100 iteration : 121.625969\n",
      "Cost after 21200 iteration : 121.473334\n",
      "Cost after 21300 iteration : 121.321283\n",
      "Cost after 21400 iteration : 121.169812\n",
      "Cost after 21500 iteration : 121.018918\n",
      "Cost after 21600 iteration : 120.868595\n",
      "Cost after 21700 iteration : 120.718839\n",
      "Cost after 21800 iteration : 120.569645\n",
      "Cost after 21900 iteration : 120.421010\n",
      "Cost after 22000 iteration : 120.272929\n",
      "Cost after 22100 iteration : 120.125399\n",
      "Cost after 22200 iteration : 119.978415\n",
      "Cost after 22300 iteration : 119.831972\n",
      "Cost after 22400 iteration : 119.686068\n",
      "Cost after 22500 iteration : 119.540698\n",
      "Cost after 22600 iteration : 119.395859\n",
      "Cost after 22700 iteration : 119.251546\n",
      "Cost after 22800 iteration : 119.107756\n",
      "Cost after 22900 iteration : 118.964485\n",
      "Cost after 23000 iteration : 118.821730\n",
      "Cost after 23100 iteration : 118.679487\n",
      "Cost after 23200 iteration : 118.537751\n",
      "Cost after 23300 iteration : 118.396521\n",
      "Cost after 23400 iteration : 118.255792\n",
      "Cost after 23500 iteration : 118.115561\n",
      "Cost after 23600 iteration : 117.975825\n",
      "Cost after 23700 iteration : 117.836580\n",
      "Cost after 23800 iteration : 117.697822\n",
      "Cost after 23900 iteration : 117.559550\n",
      "Cost after 24000 iteration : 117.421758\n",
      "Cost after 24100 iteration : 117.284446\n",
      "Cost after 24200 iteration : 117.147608\n",
      "Cost after 24300 iteration : 117.011242\n",
      "Cost after 24400 iteration : 116.875345\n",
      "Cost after 24500 iteration : 116.739914\n",
      "Cost after 24600 iteration : 116.604946\n",
      "Cost after 24700 iteration : 116.470438\n",
      "Cost after 24800 iteration : 116.336387\n",
      "Cost after 24900 iteration : 116.202790\n",
      "Cost after 25000 iteration : 116.069645\n",
      "Cost after 25100 iteration : 115.936948\n",
      "Cost after 25200 iteration : 115.804696\n",
      "Cost after 25300 iteration : 115.672888\n",
      "Cost after 25400 iteration : 115.541520\n",
      "Cost after 25500 iteration : 115.410589\n",
      "Cost after 25600 iteration : 115.280093\n",
      "Cost after 25700 iteration : 115.150029\n",
      "Cost after 25800 iteration : 115.020395\n",
      "Cost after 25900 iteration : 114.891187\n",
      "Cost after 26000 iteration : 114.762405\n",
      "Cost after 26100 iteration : 114.634044\n",
      "Cost after 26200 iteration : 114.506102\n",
      "Cost after 26300 iteration : 114.378577\n",
      "Cost after 26400 iteration : 114.251467\n",
      "Cost after 26500 iteration : 114.124769\n",
      "Cost after 26600 iteration : 113.998480\n",
      "Cost after 26700 iteration : 113.872599\n",
      "Cost after 26800 iteration : 113.747122\n",
      "Cost after 26900 iteration : 113.622049\n",
      "Cost after 27000 iteration : 113.497375\n",
      "Cost after 27100 iteration : 113.373099\n",
      "Cost after 27200 iteration : 113.249219\n",
      "Cost after 27300 iteration : 113.125733\n",
      "Cost after 27400 iteration : 113.002638\n",
      "Cost after 27500 iteration : 112.879932\n",
      "Cost after 27600 iteration : 112.757613\n",
      "Cost after 27700 iteration : 112.635679\n",
      "Cost after 27800 iteration : 112.514127\n",
      "Cost after 27900 iteration : 112.392956\n",
      "Cost after 28000 iteration : 112.272163\n",
      "Cost after 28100 iteration : 112.151747\n",
      "Cost after 28200 iteration : 112.031705\n",
      "Cost after 28300 iteration : 111.912035\n",
      "Cost after 28400 iteration : 111.792736\n",
      "Cost after 28500 iteration : 111.673805\n",
      "Cost after 28600 iteration : 111.555240\n",
      "Cost after 28700 iteration : 111.437040\n",
      "Cost after 28800 iteration : 111.319202\n",
      "Cost after 28900 iteration : 111.201724\n",
      "Cost after 29000 iteration : 111.084606\n",
      "Cost after 29100 iteration : 110.967844\n",
      "Cost after 29200 iteration : 110.851436\n",
      "Cost after 29300 iteration : 110.735382\n",
      "Cost after 29400 iteration : 110.619679\n",
      "Cost after 29500 iteration : 110.504326\n",
      "Cost after 29600 iteration : 110.389320\n",
      "Cost after 29700 iteration : 110.274659\n",
      "Cost after 29800 iteration : 110.160343\n",
      "Cost after 29900 iteration : 110.046369\n",
      "Y_pred_train shape (1, 456)\n",
      "Y_pred_valid shape (1, 57)\n",
      "train accuracy: 63.59649122807017 %\n",
      "Validation accuracy: 61.40350877192983 %\n"
     ]
    }
   ],
   "source": [
    "Final = model(X_train, X_valid, Y_train, Y_valid, num_iterations = 30000, learning_rate = 0.013)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
